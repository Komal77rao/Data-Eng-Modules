{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Komal77rao/Data-Eng-Modules/blob/main/8-testing/2-introducing-pytest/2-introducing-pytest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqQbXmqM8h8j"
      },
      "source": [
        "# Introducing Pytest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvRJ5-4Z8h89"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjwtxASJ8h8-"
      },
      "source": [
        "In the last lesson, we saw some of the virtues of testing.  Testing is just a way to write code that automatically checks our work.  In this lesson, let's see how to write tests with the `pytest` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq0OjAV68h9B"
      },
      "source": [
        "### Writing Tests in Pytest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfww5bbb8h9K"
      },
      "source": [
        "Here is how we can write a tests with Pytest.  \n",
        "\n",
        "We first define the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "exENYSNy8h9P"
      },
      "outputs": [],
      "source": [
        "# test_tracks.py\n",
        "def clean_track(track):\n",
        "    # We left something out of this method\n",
        "    return track.split(' - ')[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQTL8qPB8h9T"
      },
      "source": [
        "And then we write a function that begins with `test_` that tests the function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WssNIRMw8h9V"
      },
      "outputs": [],
      "source": [
        "def test_clean_track():\n",
        "    track_name = \"When I'm Sixty-Four - Remix\"\n",
        "    assert clean_track(track_name) == \"When I'm Sixty-Four\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po2tl_Aj8h9X"
      },
      "source": [
        "> Notice that the `test_clean_track` function, calls the `clean_track` function, and then just checks that `assert` is passed a value of `True`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqFC9DPX8h9Z"
      },
      "source": [
        "So the pattern for writing a test in Pytest is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yhmzRlZp8h9a"
      },
      "outputs": [],
      "source": [
        "def test_some_function():\n",
        "    assert some_function() == 'proper return value'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VqLR3mz8h9i"
      },
      "source": [
        "### Running our tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ8-nt7v8h9j"
      },
      "source": [
        "We can run our test by executing the `pytest` command from our terminal.  Calling `pytest` will look for any files that begin with `test_` and run those files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMz_8KZ48h9l"
      },
      "source": [
        "So create a file called `test_tracks.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W0tjaRjA8h9m"
      },
      "outputs": [],
      "source": [
        "!touch test_tracks.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VoV08108h9m"
      },
      "source": [
        "And copy the following code into the file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpDhYD5E8h9m"
      },
      "source": [
        "```python\n",
        "# test_tracks.py\n",
        "\n",
        "def clean_track(track):\n",
        "    return track.split(' - ')\n",
        "\n",
        "\n",
        "def test_clean_track():\n",
        "    track_name = \"When I'm Sixty-Four - Remix\"\n",
        "    assert clean_track(track_name) == \"When I'm Sixty-Four\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vngf140r8h9n"
      },
      "source": [
        "Then run the tests in the `test_tracks.py` file simply by called pytest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f1n1s8W48h9n",
        "outputId": "c73a7c9e-1f0b-4fb5-8223-5d4934a6036a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.3, pluggy-1.3.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 1 item                                                                                   \u001b[0m\n",
            "\n",
            "test_tracks.py \u001b[31mF\u001b[0m\u001b[31m                                                                             [100%]\u001b[0m\n",
            "\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_________________________________________ test_clean_track _________________________________________\u001b[0m\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_clean_track\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        track_name = \u001b[33m\"\u001b[39;49;00m\u001b[33mWhen I\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mm Sixty-Four - Remix\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m clean_track(track_name) == \u001b[33m\"\u001b[39;49;00m\u001b[33mWhen I\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mm Sixty-Four\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert [\"When I'm Sixty-Four\", 'Remix'] == \"When I'm Sixty-Four\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where [\"When I'm Sixty-Four\", 'Remix'] = clean_track(\"When I'm Sixty-Four - Remix\")\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_tracks.py\u001b[0m:8: AssertionError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m test_tracks.py::\u001b[1mtest_clean_track\u001b[0m - assert [\"When I'm Sixty-Four\", 'Remix'] == \"When I'm Sixty-Four\"\n",
            "\u001b[31m======================================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.08s\u001b[0m\u001b[31m =========================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest test_tracks.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFns1QOe8h9r"
      },
      "source": [
        "### Debugging our errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzMkn2HC8h9u"
      },
      "source": [
        "Bummer. A big red error.\n",
        "\n",
        "Let's walk through debugging our errors in Pytest (and in general).  We read our messages from the bottom to the top.  Starting at the last line, we see that our error is occurring in line 7, and that it's an `AssertionError`.   And then in the red line above, we can see that there is an error of\n",
        "\n",
        "* `assert [\"When I'm Sixty-Four\", 'Remix'] == \"When I'm Sixty-Four\"`\n",
        "\n",
        "This makes sense, as we expect `[\"When I'm Sixty-Four\", 'Remix'] == \"When I'm Sixty-Four\"` to return `False`, thus triggering the error.\n",
        "\n",
        "So the next step is to change the `clean_track` function so that it returns a value matching `\"When I'm Sixty-Four\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4giwCMB8h9v"
      },
      "source": [
        "Looking at the clean track method, we can see that it returns a list, where we really just need the first element from that list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV7J8KbM8h9y"
      },
      "outputs": [],
      "source": [
        "def clean_track(track):\n",
        "    # We left something out of this method\n",
        "    return track.split(' - ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85lcDkoF8h9z"
      },
      "source": [
        "Update the `clean_track` method so that it passes the test.  You can check that your code is working by running the `pytest` command."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW3mpXSw8h90"
      },
      "source": [
        "### Practice debugging with tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brfHXls38h90"
      },
      "source": [
        "Reading an error message in a testing environment can take some practice.  Below our `clean_track` function, let's copy the following code into the `test_tracks.py` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E7X-0vL8h90"
      },
      "source": [
        "```python\n",
        "songs = [{'rank': 1, 'song': 'Like a Rolling Stone', 'artist': 'Bob Dylan', 'year': 1965},  {'rank': 2, 'song': 'Satisfaction', 'artist': 'The Rolling Stones', 'year': 1965}, {'rank': 5, 'song': 'Respect', 'artist': 'Aretha Franklin', 'year': 1967}]\n",
        "\n",
        "\n",
        "def find_song(songs, name):\n",
        "    found_song = [song for song in songs if song['song'] == name]\n",
        "    return next(iter(found_song), 'none')\n",
        "\n",
        "\n",
        "def test_find_song_returns_song_dict():\n",
        "    found_song = find_song(songs, 'Like a Rolling Stone')\n",
        "    assert found_song == {'rank': 1, 'song': 'Like a Rolling Stone', 'artist': 'Bob Dylan', 'year': 1965}, 'returns song dictionary'\n",
        "    \n",
        "def test_find_song_returns_none_if_no_song_found():\n",
        "    found_song = find_song(songs, 'Like Some Rolling Stone')\n",
        "    assert found_song == None, 'returns None'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iCQdIrK8h90"
      },
      "source": [
        "Now let's run `pytest` again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROUWgRMy8h90",
        "outputId": "09d41a9c-b012-479d-afce-918c66a7deeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform darwin -- Python 3.8.3, pytest-5.4.3, py-1.9.0, pluggy-0.13.1\n",
            "rootdir: /Users/jeff/Documents/jigsaw/curriculum/1-section-content/mod-1/mod-1-a-data-structures/8-testing/2-introducing-pytest\n",
            "collected 3 items                                                              \u001b[0m\n",
            "\n",
            "test_tracks.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                       [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xqaaBWr8h91"
      },
      "source": [
        "Ok, so read the line number and file where the error is showing up.  Then look to understand the error message.\n",
        "\n",
        "Finally, if necessary, change the function to get the tests passing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51nXOteS8h92"
      },
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7od9pQOy8h93"
      },
      "source": [
        "In this lesson we saw how to write and run tests with Pytest.  And then we got some practice in debugging our code with `pytest`.\n",
        "\n",
        "To write tests we define a function with in the pattern `def test_` and then inside the body of the function, we have an `assert` statement where we compare the return value fo a function to what it should equal.\n",
        "\n",
        "Then we saw that we can run our tests with the `pytest` command.  Pytest will look for and run any files that begin with `test_` in their filename.  \n",
        "\n",
        "Finally, we practiced debugging our code with Pytest.  The important part here is to start from the bottom, see the line number that is failing, then move upwards to understand the error message.  Finally, we fix the code and run `pytest` again."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}